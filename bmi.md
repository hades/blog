### A way how brain machine interface could work.

tldr: brain's output throughtput should be low.

Interface consists in two parts, a good one and a bad one.

The good one is a FullblownHD 3D multielectrode pixel display in visual cortex.
A seres of needles (or whatever) in brain (maybe rougly arranged as a cube).
Works as input to a brain, no need to record a lot of data from them.

To teach a human understand 3d image we cant transmit a 3d video taken from subject's body movements.
Or image of a simple shape that subject is moving in his hands.
The goal is to transmit a real time image that human sees and fully understands right now
and hope that brain will pick up a better source of information about what human is holding in his hands.

And a bad one is so bad it can't even right click.
A simple switch, that will communicate to the machine only two commands: <<| and |>>.
One electrode (or even EEG) in motor cortex will do.
It will drive a playback of an offline 3d video in FHD 3d array backwards or forwards.
Like youtube360 but better (sell it to google, hm?)
Make it like a joystick or spring to be able to control acceleration too.

Later we will be able to teach him Kung Fu.

Further research can be done in making a feedback channel more sophisticated.
To be able to know what point of 3d image is the most interesting to a human we can choose a couple of feedback electrodes.
Again, threre is no need for a lot of recording power.
The exact point of interest will be calculated based on average signal between several electrodes.
To teach human to transmit to this electrodes we can lit up or scale up part of the image where this signals is detected.
It's like brightness or zoom control but spatial.
Thus the human will be able to choose between various netflix shows.

Don't forget to make a kill switch in prefrontal cortex.
